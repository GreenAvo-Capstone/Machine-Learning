{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV8Hv5Pykbwg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H15rckFFlKH4",
        "outputId": "33541f89-c233-4196-bc13-ca4e4ce746ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Machine-Learning'...\n",
            "remote: Enumerating objects: 15054, done.\u001b[K\n",
            "remote: Counting objects: 100% (315/315), done.\u001b[K\n",
            "remote: Compressing objects: 100% (295/295), done.\u001b[K\n",
            "remote: Total 15054 (delta 16), reused 307 (delta 13), pack-reused 14739\u001b[K\n",
            "Receiving objects: 100% (15054/15054), 412.14 MiB | 26.13 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "Updating files: 100% (29425/29425), done.\n"
          ]
        }
      ],
      "source": [
        "# Menggunakan tanda seru (!) untuk menjalankan perintah shell\n",
        "!git clone https://github.com/GreenAvo-Capstone/Machine-Learning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVklIgUdlNLk",
        "outputId": "d2860c01-66b6-4a5d-c431-999ea7c19fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset berhasil diunduh.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Cek apakah direktori dataset sudah ada\n",
        "dataset_dir = './Machine-Learning/dataset'\n",
        "if os.path.exists(dataset_dir):\n",
        "    print(\"Dataset berhasil diunduh.\")\n",
        "else:\n",
        "    print(\"Dataset tidak ditemukan.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vfGAtzfk9WT"
      },
      "outputs": [],
      "source": [
        "path_train = os.path.join(dataset_dir, 'train')\n",
        "path_val = os.path.join(dataset_dir, 'val')\n",
        "path_test = os.path.join(dataset_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo2A_Wnjk9Yw"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "img_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl2cTj9Pk9bG",
        "outputId": "545c0a17-6227-4dd1-d484-73d1131c2209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11032 files belonging to 5 classes.\n",
            "Found 2205 files belonging to 5 classes.\n",
            "Found 1473 files belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(path_train, shuffle=True, batch_size = BATCH_SIZE, image_size = (img_size, img_size), label_mode = \"categorical\")\n",
        "valid_ds = tf.keras.utils.image_dataset_from_directory(path_val, shuffle=True, batch_size = BATCH_SIZE, image_size = (img_size, img_size), label_mode = \"categorical\")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(path_test, shuffle=False, batch_size = BATCH_SIZE, image_size = (img_size, img_size), label_mode = \"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear previous sessions\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Define image size\n",
        "img_size = 224\n",
        "\n",
        "# Load datasets\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    path_train,\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    path_val,\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    path_test,\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "# Get class names from training dataset\n",
        "class_names = train_ds.class_names\n",
        "num_class = len(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7UKhLfG3VC",
        "outputId": "4ddf1c07-5042-4aab-ff0d-8afdab89e0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11032 files belonging to 5 classes.\n",
            "Found 2205 files belonging to 5 classes.\n",
            "Found 1473 files belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQP1lh5Xk9da",
        "outputId": "70a241a2-69af-43b5-f51c-afb80a509724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
            "12683000/12683000 [==============================] - 1s 0us/step\n",
            "Images shape: (32, 224, 224, 3)\n",
            "Labels shape: (32,)\n"
          ]
        }
      ],
      "source": [
        "# Load MobileNetV3Large with pre-trained weights and make it trainable\n",
        "base_model = tf.keras.applications.MobileNetV3Large(input_shape=(img_size, img_size, 3), include_top=False, pooling=\"max\")\n",
        "base_model.trainable = True\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((img_size, img_size, 3), name=\"Input\", dtype=tf.float32),\n",
        "    tf.keras.layers.Rescaling(scale=1./255, name=\"Rescale_Layer\"),\n",
        "    base_model,\n",
        "    tf.keras.layers.Dense(128, activation='selu', kernel_initializer=\"lecun_normal\", name=\"FC\"),\n",
        "    tf.keras.layers.Dense(num_class, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1, name='precision'),\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1, name='recall')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply additional preprocessing if needed\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, [img_size, img_size])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "    train_ds = train_ds.map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    valid_ds = valid_ds.map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    test_ds = test_ds.map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Check the shapes of a batch of images and labels\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(f\"Images shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "\n",
        "# Define callbacks\n",
        "    bestCB = tf.keras.callbacks.ModelCheckpoint(filepath=f'best_model.h5', verbose=1, save_best_only=True)\n",
        "    lrCB = tf.keras.callbacks.ReduceLROnPlateau(verbose=1, min_lr=1e-20, patience=5)\n",
        "    esCB = tf.keras.callbacks.EarlyStopping(patience=45, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b3pej2NSk9fv",
        "outputId": "51681dce-16d4-488a-a45e-1bbc04791902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.1761 - accuracy: 0.6171 - precision: 0.6171 - recall: 0.6171\n",
            "Epoch 1: val_loss improved from inf to 3.56506, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r345/345 [==============================] - 92s 162ms/step - loss: 1.1761 - accuracy: 0.6171 - precision: 0.6171 - recall: 0.6171 - val_loss: 3.5651 - val_accuracy: 0.1946 - val_precision: 0.1946 - val_recall: 0.1946 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.7517 - precision: 0.7517 - recall: 0.7517\n",
            "Epoch 2: val_loss did not improve from 3.56506\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.6070 - accuracy: 0.7517 - precision: 0.7517 - recall: 0.7517 - val_loss: 4.7817 - val_accuracy: 0.1946 - val_precision: 0.1946 - val_recall: 0.1946 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8192 - precision: 0.8192 - recall: 0.8192\n",
            "Epoch 3: val_loss improved from 3.56506 to 2.75477, saving model to best_model.h5\n",
            "345/345 [==============================] - 56s 161ms/step - loss: 0.4487 - accuracy: 0.8192 - precision: 0.8192 - recall: 0.8192 - val_loss: 2.7548 - val_accuracy: 0.1587 - val_precision: 0.1587 - val_recall: 0.1587 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.8539 - precision: 0.8539 - recall: 0.8539\n",
            "Epoch 4: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 50s 144ms/step - loss: 0.3632 - accuracy: 0.8539 - precision: 0.8539 - recall: 0.8539 - val_loss: 3.0399 - val_accuracy: 0.1791 - val_precision: 0.1791 - val_recall: 0.1791 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.8935 - precision: 0.8935 - recall: 0.8935\n",
            "Epoch 5: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.2740 - accuracy: 0.8935 - precision: 0.8935 - recall: 0.8935 - val_loss: 3.9125 - val_accuracy: 0.1905 - val_precision: 0.1905 - val_recall: 0.1905 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9310 - precision: 0.9310 - recall: 0.9310\n",
            "Epoch 6: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 55s 159ms/step - loss: 0.1824 - accuracy: 0.9310 - precision: 0.9310 - recall: 0.9310 - val_loss: 4.1669 - val_accuracy: 0.2231 - val_precision: 0.2231 - val_recall: 0.2231 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476\n",
            "Epoch 7: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.1418 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - val_loss: 4.8676 - val_accuracy: 0.2240 - val_precision: 0.2240 - val_recall: 0.2240 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9632 - precision: 0.9632 - recall: 0.9632\n",
            "Epoch 8: val_loss did not improve from 2.75477\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "345/345 [==============================] - 52s 148ms/step - loss: 0.1052 - accuracy: 0.9632 - precision: 0.9632 - recall: 0.9632 - val_loss: 4.1117 - val_accuracy: 0.2249 - val_precision: 0.2249 - val_recall: 0.2249 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9844 - precision: 0.9844 - recall: 0.9844\n",
            "Epoch 9: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.0561 - accuracy: 0.9844 - precision: 0.9844 - recall: 0.9844 - val_loss: 5.0586 - val_accuracy: 0.2240 - val_precision: 0.2240 - val_recall: 0.2240 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9947 - precision: 0.9947 - recall: 0.9947\n",
            "Epoch 10: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0328 - accuracy: 0.9947 - precision: 0.9947 - recall: 0.9947 - val_loss: 4.6664 - val_accuracy: 0.2249 - val_precision: 0.2249 - val_recall: 0.2249 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970\n",
            "Epoch 11: val_loss did not improve from 2.75477\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.0260 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - val_loss: 3.5154 - val_accuracy: 0.2794 - val_precision: 0.2794 - val_recall: 0.2794 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9986 - precision: 0.9986 - recall: 0.9986\n",
            "Epoch 12: val_loss improved from 2.75477 to 2.48843, saving model to best_model.h5\n",
            "345/345 [==============================] - 56s 159ms/step - loss: 0.0198 - accuracy: 0.9986 - precision: 0.9986 - recall: 0.9986 - val_loss: 2.4884 - val_accuracy: 0.4181 - val_precision: 0.4181 - val_recall: 0.4181 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9988 - precision: 0.9988 - recall: 0.9988\n",
            "Epoch 13: val_loss improved from 2.48843 to 2.42943, saving model to best_model.h5\n",
            "345/345 [==============================] - 52s 149ms/step - loss: 0.0164 - accuracy: 0.9988 - precision: 0.9988 - recall: 0.9988 - val_loss: 2.4294 - val_accuracy: 0.4073 - val_precision: 0.4073 - val_recall: 0.4073 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9991 - precision: 0.9991 - recall: 0.9991\n",
            "Epoch 14: val_loss did not improve from 2.42943\n",
            "345/345 [==============================] - 51s 145ms/step - loss: 0.0149 - accuracy: 0.9991 - precision: 0.9991 - recall: 0.9991 - val_loss: 2.6133 - val_accuracy: 0.4236 - val_precision: 0.4236 - val_recall: 0.4236 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
            "Epoch 15: val_loss did not improve from 2.42943\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0127 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995 - val_loss: 2.7425 - val_accuracy: 0.4472 - val_precision: 0.4472 - val_recall: 0.4472 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992\n",
            "Epoch 16: val_loss did not improve from 2.42943\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0119 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992 - val_loss: 2.8940 - val_accuracy: 0.4544 - val_precision: 0.4544 - val_recall: 0.4544 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
            "Epoch 17: val_loss did not improve from 2.42943\n",
            "345/345 [==============================] - 55s 159ms/step - loss: 0.0100 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995 - val_loss: 2.8251 - val_accuracy: 0.4635 - val_precision: 0.4635 - val_recall: 0.4635 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9994 - precision: 0.9994 - recall: 0.9994\n",
            "Epoch 18: val_loss improved from 2.42943 to 2.29198, saving model to best_model.h5\n",
            "345/345 [==============================] - 52s 149ms/step - loss: 0.0102 - accuracy: 0.9994 - precision: 0.9994 - recall: 0.9994 - val_loss: 2.2920 - val_accuracy: 0.4875 - val_precision: 0.4875 - val_recall: 0.4875 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
            "Epoch 19: val_loss improved from 2.29198 to 2.12685, saving model to best_model.h5\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.0089 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995 - val_loss: 2.1269 - val_accuracy: 0.5084 - val_precision: 0.5084 - val_recall: 0.5084 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
            "Epoch 20: val_loss improved from 2.12685 to 1.86674, saving model to best_model.h5\n",
            "345/345 [==============================] - 52s 149ms/step - loss: 0.0075 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995 - val_loss: 1.8667 - val_accuracy: 0.5533 - val_precision: 0.5533 - val_recall: 0.5533 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 21: val_loss improved from 1.86674 to 1.34758, saving model to best_model.h5\n",
            "345/345 [==============================] - 50s 145ms/step - loss: 0.0066 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3476 - val_accuracy: 0.6277 - val_precision: 0.6277 - val_recall: 0.6277 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997\n",
            "Epoch 22: val_loss improved from 1.34758 to 0.99786, saving model to best_model.h5\n",
            "345/345 [==============================] - 57s 163ms/step - loss: 0.0056 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.9979 - val_accuracy: 0.6780 - val_precision: 0.6780 - val_recall: 0.6780 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
            "Epoch 23: val_loss did not improve from 0.99786\n",
            "345/345 [==============================] - 52s 148ms/step - loss: 0.0052 - accuracy: 0.9998 - precision: 0.9998 - recall: 0.9998 - val_loss: 1.0862 - val_accuracy: 0.6862 - val_precision: 0.6862 - val_recall: 0.6862 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997\n",
            "Epoch 24: val_loss did not improve from 0.99786\n",
            "345/345 [==============================] - 52s 148ms/step - loss: 0.0047 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 1.1276 - val_accuracy: 0.6980 - val_precision: 0.6980 - val_recall: 0.6980 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9996\n",
            "Epoch 25: val_loss did not improve from 0.99786\n",
            "345/345 [==============================] - 52s 148ms/step - loss: 0.0045 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9996 - val_loss: 1.0874 - val_accuracy: 0.7098 - val_precision: 0.7098 - val_recall: 0.7098 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997\n",
            "Epoch 26: val_loss improved from 0.99786 to 0.87371, saving model to best_model.h5\n",
            "345/345 [==============================] - 51s 145ms/step - loss: 0.0041 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.8737 - val_accuracy: 0.7664 - val_precision: 0.7664 - val_recall: 0.7664 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0030 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.7565 - val_precision: 0.7565 - val_recall: 0.7565 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997\n",
            "Epoch 28: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0036 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 1.1348 - val_accuracy: 0.7129 - val_precision: 0.7129 - val_recall: 0.7129 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 29: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.0024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7560 - val_precision: 0.7560 - val_recall: 0.7560 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 30: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 55s 158ms/step - loss: 0.0024 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.9604 - val_accuracy: 0.7673 - val_precision: 0.7673 - val_recall: 0.7673 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 31: val_loss did not improve from 0.87371\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "345/345 [==============================] - 50s 144ms/step - loss: 0.0030 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 1.0979 - val_accuracy: 0.7433 - val_precision: 0.7433 - val_recall: 0.7433 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 32: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0018 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 1.0247 - val_accuracy: 0.7533 - val_precision: 0.7533 - val_recall: 0.7533 - lr: 1.0000e-06\n",
            "Epoch 33/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 33: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 52s 147ms/step - loss: 0.0017 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 1.0492 - val_accuracy: 0.7565 - val_precision: 0.7565 - val_recall: 0.7565 - lr: 1.0000e-06\n",
            "Epoch 34/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 34: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - lr: 1.0000e-06\n",
            "Epoch 35/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 35: val_loss did not improve from 0.87371\n",
            "345/345 [==============================] - 50s 144ms/step - loss: 0.0019 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.8905 - val_accuracy: 0.7882 - val_precision: 0.7882 - val_recall: 0.7882 - lr: 1.0000e-06\n",
            "Epoch 36/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 36: val_loss improved from 0.87371 to 0.81719, saving model to best_model.h5\n",
            "345/345 [==============================] - 56s 159ms/step - loss: 0.0017 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.8172 - val_accuracy: 0.8050 - val_precision: 0.8050 - val_recall: 0.8050 - lr: 1.0000e-06\n",
            "Epoch 37/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 37: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 51s 146ms/step - loss: 0.0016 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8430 - val_accuracy: 0.7964 - val_precision: 0.7964 - val_recall: 0.7964 - lr: 1.0000e-06\n",
            "Epoch 38/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 38: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.7959 - val_precision: 0.7959 - val_recall: 0.7959 - lr: 1.0000e-06\n",
            "Epoch 39/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 39: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 51s 147ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8692 - val_accuracy: 0.7932 - val_precision: 0.7932 - val_recall: 0.7932 - lr: 1.0000e-06\n",
            "Epoch 40/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 40: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 50s 142ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8389 - val_accuracy: 0.7964 - val_precision: 0.7964 - val_recall: 0.7964 - lr: 1.0000e-06\n",
            "Epoch 41/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 41: val_loss did not improve from 0.81719\n",
            "\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "345/345 [==============================] - 51s 145ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8256 - val_accuracy: 0.8005 - val_precision: 0.8005 - val_recall: 0.8005 - lr: 1.0000e-06\n",
            "Epoch 42/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 42: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 50s 145ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - lr: 1.0000e-07\n",
            "Epoch 43/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 43: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 52s 148ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.7995 - val_precision: 0.7995 - val_recall: 0.7995 - lr: 1.0000e-07\n",
            "Epoch 44/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999\n",
            "Epoch 44: val_loss did not improve from 0.81719\n",
            "345/345 [==============================] - 50s 143ms/step - loss: 0.0015 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.8199 - val_accuracy: 0.8023 - val_precision: 0.8023 - val_recall: 0.8023 - lr: 1.0000e-07\n",
            "Epoch 45/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7db6e0e72d04>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestCB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrCB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesCB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1854\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                         )\n\u001b[0;32m-> 1856\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1857\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m                         ):\n\u001b[1;32m   2295\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2297\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = valid_ds,\n",
        "    epochs = 100,\n",
        "    callbacks=[bestCB, lrCB, esCB]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QSi7Qm3k9kk"
      },
      "outputs": [],
      "source": [
        "model.save(\"./checkpoint/latest/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label = \"Training Loss\")\n",
        "plt.plot(history.history['val_loss'], label = \"Validation Loss\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"Loss History\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['precision'], label = \"Training Precision\")\n",
        "plt.plot(history.history['val_precision'], label = \"Validation Precision\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"Precision History\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zltQhN46jMcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhfFN6QCk9nE"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = history.epoch\n",
        "\n",
        "plt.plot(epochs, acc, label='Train Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model's Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs[10:], loss[10:], label='Train Loss')\n",
        "plt.plot(epochs[10:], val_loss[10:], label='Validation Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Model's Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw9tstsck9p4"
      },
      "outputs": [],
      "source": [
        "# Load iterasi terakhir\n",
        "# model = tf.keras.models.load_model(\"./checkpoint/latest/\")\n",
        "\n",
        "# Load terbaik\n",
        "best_model = tf.keras.models.load_model(f'best_model.h5')\n",
        "\n",
        "# Evaluasi model pada data testing\n",
        "loss, accuracy, precision, recall = best_model.evaluate(test_ds)\n",
        "print(\"Loss pada data testing:\", loss)\n",
        "print(\"Akurasi pada data testing:\", accuracy)\n",
        "print(\"Precision pada data testing:\", precision)\n",
        "print(\"Recall pada data testing:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi kelas untuk setiap gambar di data testing\n",
        "predictions = best_model.predict(test_ds)\n",
        "predicted_classes = tf.math.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "4GajH9YIHPJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan beberapa contoh prediksi\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(5):  # Tampilkan 5 gambar pertama\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(f\"Prediksi: {class_names[predicted_classes[i]]}, \\\n",
        "                  Aktual: {class_names[labels[i]]}\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "k8TAYCieHPLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan Model\n",
        "model.save('model_alpukat.h5')"
      ],
      "metadata": {
        "id": "8RBQnZ0g1Cfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KSjZtNHQ00Oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the Model to TensorFlow Lite"
      ],
      "metadata": {
        "id": "lIwlrH7n07cL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL0IA3Qmk9sM"
      },
      "outputs": [],
      "source": [
        "# Optimize size\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(f'best_model.h5')\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_file = pathlib.Path('model size.tflite')\n",
        "tflite_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBkn0C8Rk9uo"
      },
      "outputs": [],
      "source": [
        "# Optimize latency\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(f'best_model.h5')\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_file = pathlib.Path('model latency.tflite')\n",
        "tflite_file.write_bytes(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}